{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 . Build a Classification Model with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "RExqO1ZWVD1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install & Import Required Libraries"
      ],
      "metadata": {
        "id": "IDEsG6wRVMlg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZHOFnguK_Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec193cae-68d4-4396-d9e2-f82bc1096aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "ZP5fko_WVRD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Spark Session"
      ],
      "metadata": {
        "id": "ik8Z2IzbVWeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "try:\n",
        "    spark = SparkSession.builder \\\n",
        "        .appName(\"ClassificationModel\") \\\n",
        "        .getOrCreate()\n",
        "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "    print(\"Spark session initialized successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Spark session: {e}\")\n",
        "    exit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBeW-OgvVTmX",
        "outputId": "87cb768d-ac4f-4f9e-d5c7-88ebb5c35341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark session initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Titanic Dataset"
      ],
      "metadata": {
        "id": "1A4g2S4hVe0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "titanic_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "local_path = \"titanic.csv\"  # Specify a local path to save the file\n",
        "\n",
        "# Download the file\n",
        "urllib.request.urlretrieve(titanic_url, local_path)\n",
        "\n",
        "# Read the file into a PySpark DataFrame\n",
        "titanic_df = spark.read.csv(local_path, header=True, inferSchema=True)\n",
        "\n",
        "# Optionally, delete the local file after loading\n",
        "# os.remove(local_path)\n",
        "\n",
        "titanic_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8oHMe-xVbcI",
        "outputId": "b1a8e59f-7a9a-4a6c-87eb-0e63c967b06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing (Vector Assembler + Label Indexing)"
      ],
      "metadata": {
        "id": "_1V4MbzAVzfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Weâ€™ll select important columns and handle nulls\n",
        "\n",
        "# Select columns\n",
        "columns = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "df = titanic_df.select(columns)\n",
        "\n",
        "# Drop rows with null values\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "ki7KNPPWViww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert categorical Sex to numeric:\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndexed\")\n",
        "df = indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "1XKJcVaFV4Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assemble all features into one vector\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"Pclass\", \"SexIndexed\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df = assembler.transform(df)"
      ],
      "metadata": {
        "id": "oL_TqTIxV6QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "-NRxIbM8WtDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "Iq_UqybpWrQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Classifier (Random Forest)"
      ],
      "metadata": {
        "id": "wiIGBEb1WxOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "model = rf.fit(train_data)"
      ],
      "metadata": {
        "id": "bw1VfqNeWu-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model"
      ],
      "metadata": {
        "id": "SkbhAhxRXFF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Survived\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy = {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EsN_xryXDyZ",
        "outputId": "13f1fea3-1827-405e-dbae-017eb87a0e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy = 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "OucAFslpXd9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}